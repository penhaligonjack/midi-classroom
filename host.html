<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Host – MIDI Classroom (Listener)</title>
  <style>
    body { font-family: system-ui, -apple-system, sans-serif; padding: 20px; max-width:700px; }
    label { display:block; margin-top:10px; }
    .row { display:flex; gap:8px; align-items:center; }
    #log { background:#f6f6f6; padding:8px; height:120px; overflow:auto; margin-top:10px; white-space:pre-wrap;}
  </style>
</head>
<body>
  <h1>Host — MIDI Classroom</h1>

  <div class="row">
    <label>Room:</label>
    <input id="room" value="room1" style="width:160px">
    <button id="connectBtn">Connect as Host</button>
    <span id="status" style="margin-left:10px;">Not connected</span>
  </div>

  <label style="margin-top:14px;">Volume: <span id="volPct">80%</span></label>
  <input id="volume" type="range" min="0" max="100" value="80" style="width:100%">

  <div id="log"></div>

<script>
/* ===== HOST PAGE: polyphonic piano synth + WS listener ===== */

const logEl = document.getElementById('log');
function log(...a){ console.log(...a); logEl.textContent += a.join(' ') + '\n'; logEl.scrollTop = logEl.scrollHeight; }

const statusEl = document.getElementById('status');
function setStatus(s){ statusEl.textContent = s; log('STATUS:', s); }

// Audio context + polyphony setup
let audioCtx = null;
const master = { gainNode: null };
const voices = new Map(); // key -> {osc1, osc2, filter, gain, stopTimer}

function ensureAudio() {
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    master.gainNode = audioCtx.createGain();
    master.gainNode.gain.value = Number(document.getElementById('volume').value) / 100;
    master.gainNode.connect(audioCtx.destination);
  }
}

// update master volume
document.getElementById('volume').addEventListener('input', (ev) => {
  const v = Number(ev.target.value)/100;
  document.getElementById('volPct').innerText = Math.round(v*100) + '%';
  if (master.gainNode) master.gainNode.gain.setValueAtTime(v, audioCtx.currentTime || 0);
});

// create a voice for a note (polyphonic)
function startVoice(note, velocity){
  ensureAudio();
  const now = audioCtx.currentTime;
  const freq = 440 * Math.pow(2, (note - 69) / 12);

  // main tone (triangle)
  const osc1 = audioCtx.createOscillator();
  osc1.type = 'triangle';
  osc1.frequency.value = freq;

  // brightness layer (small sawtooth)
  const osc2 = audioCtx.createOscillator();
  osc2.type = 'sawtooth';
  osc2.frequency.value = freq * 2; // octave harmonic for body

  // filter to warm the tone
  const filter = audioCtx.createBiquadFilter();
  filter.type = 'lowpass';
  const brightness = 1000 + (velocity/127) * 4000;
  filter.frequency.setValueAtTime(brightness, now);
  filter.Q.value = 0.7;

  // gain envelope node
  const gain = audioCtx.createGain();
  const peak = 0.25 * (velocity/127); // absolute loudness, scaled (host volume applied by master)
  // ADSR-like envelope
  const attack = 0.005;
  const decay = 0.12;
  const sustain = 0.6;
  const release = 1.5;

  gain.gain.setValueAtTime(0, now);
  gain.gain.linearRampToValueAtTime(peak, now + attack);
  gain.gain.linearRampToValueAtTime(peak * sustain, now + attack + decay);

  // connect nodes
  osc1.connect(filter);
  osc2.connect(filter);
  filter.connect(gain);
  gain.connect(master.gainNode);

  osc1.start(now);
  osc2.start(now);

  const key = note; // host only uses note as key (no channel handling)
  voices.set(key, { osc1, osc2, filter, gain, release, stopTime: null });

  return key;
}

function releaseVoice(note){
  if (!audioCtx) return;
  const v = voices.get(note);
  if (!v) return;
  const now = audioCtx.currentTime;
  // ramp to 0 using exponential ramp for natural decay
  v.gain.gain.cancelScheduledValues(now);
  v.gain.gain.setTargetAtTime(0.0001, now, v.release);
  // stop oscillators after release+0.5s
  const stopAt = now + v.release + 0.6;
  try { v.osc1.stop(stopAt); v.osc2.stop(stopAt); } catch(e){}
  // cleanup after stop
  setTimeout(()=> voices.delete(note), Math.round((v.release+0.7)*1000));
}

// handle incoming MIDI message array [status,data1,data2]
function handleIncomingMidi(data){
  const status = data[0];
  const note = data[1];
  const velocity = data[2] || 0;
  const cmd = status & 0xf0;

  if ((cmd === 0x90 && velocity > 0)) {
    // note on
    if (!audioCtx) ensureAudio();
    startVoice(note, velocity);
  } else if (cmd === 0x80 || (cmd === 0x90 && velocity === 0)) {
    // note off
    releaseVoice(note);
  }
}

// WebSocket
let ws = null;
function wsUrl(){
  if (location.hostname === 'localhost' || location.protocol === 'file:') return 'ws://localhost:8080';
  return `wss://${window.location.host}`;
}

document.getElementById('connectBtn').addEventListener('click', () => {
  const room = document.getElementById('room').value || 'room1';
  setStatus('Connecting to ' + wsUrl());
  ws = new WebSocket(wsUrl());

  ws.onopen = () => {
    setStatus('Connected as host (room: ' + room + ')');
    // join message
    ws.send(JSON.stringify({ type: 'join', role: 'host', room }));
    // ensure audio context created after user gesture
    ensureAudio();
    log('Ready to receive MIDI from students');
  };

  ws.onmessage = (ev) => {
    try {
      const msg = JSON.parse(ev.data);
      if (msg.type === 'midi' && Array.isArray(msg.data)) {
        handleIncomingMidi(msg.data);
      } else {
        log('WS msg:', msg);
      }
    } catch (e) {
      log('WS parse error', e);
    }
  };

  ws.onclose = () => setStatus('Disconnected');
  ws.onerror = (e) => {
    setStatus('WebSocket error (see console)');
    log('WS error', e);
  };
});
</script>
</body>
</html>
